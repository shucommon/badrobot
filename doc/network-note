## SCSI/iSCSI/FC/SAS
"SAN" is a term for a network used to provide (block) storage access. It can be anything.

SCSI is a family of storage protocols that all share a common core but have more or less subtle differences (apart from the obvious, physical ones). Examples are Parallel SCSI (obsolete), SSA (obsolete), Fibre Channel, Firewire (obsolete), SAS, iSCSI.

SAS and Fibre Channel are two different SCSI variants that each define they're own physical protocols and thus, infrastructure.

iSCSI is another SCSI variant but instead of defining a physical implementation, it sits on top of TCP/IP which most often runs over Ethernet.

Since all three are SCSI implementations, there are ways to make them compatible which each other (by multi-protocol bridging) or at least use them on the same physical infrastructure (e.g. FCoE). Bridging is costly however and most often you use just a single flavor or sometimes multiple in parallel.

PS: Parallel SCSI (SPI) is ancient and long obsolete. It was the foundation for the modern variants though and logically, all things SCSI use the same command protocol.


https://www.icc-usa.com/insights/sas-sata-and-iscsi-a-tutorial/

Yesterday there was a great piece over at TechRepublic on the confusing intersection of SAS, SATA and iSCSI arrays. For anyone who has ever had a difficult time understanding and differentiating these technologies, this is a very valuable resource. Excerpts are cross-posted below.
SATA and SAS are storage interface and bus types designed to aid in the movement of data from one place to another. Think of SAS and SATA as different kinds of computer interfaces, such as PCI Express, but there are actually multiple components that make up the overall SAS architecture.

Initiators. The initiator is the SAS controller to which SAS expanders or targets can be connected.
Expanders. Expanders sit between initiators and targets, but can also connect to other expanders, as you can see in Figure A. Expanders are sort of like network switches in that they can direct traffic and they provide the ability to scale the SAS architecture beyond single port limits.
Targets. A target is either a SAS drive or a SATA disk. SATA disks can be connected to SAS expanders and initiators, but do not perform quite as well as SAS disks.
Each drive has its own host interface (SAS or SATA) which are connected to an initiator or an expander. The initiator, functioning as the system controller, communicates with the SSD using the appropriate commands as dictated by the host interface (again, SAS or SATA.)

In other words, the SSD functions no differently than a hard-disk in terms of how it the interfaces (SAS or SATA) work. It simply utilizes a different method of storing the data.

Now… let’s introduce iSCSI
It’s either hardware- or software-based and controls communications with the Ethernet-based storage array. By virtue of the fact that the system is using Ethernet for storage traffic, speeds of both 1 Gbps and 10 Gbps are supported. In an iSCSI storage network, SCSI commands originate on the host, at which point, they are encapsulated inside TCP/IP packets. These TCP/IP packets then traverse the Ethernet network just like any other network traffic. At the storage array side of the equation, these packets are received and the SCSI commands are extracted from the TCP/IP packet and passed on to the storage device for execution. Data that is transmitted back to the host undergoes this same encapsulation process.
Basically, iSCSI adds some extra processor load because of the encapsulation process which takes time. We can think of iSCSI as a “storage transportation method.” In that sense, they resemble SATA and SAS in dealing with how the data is moved around (vs. SSD which deals with how the data is stored.) While this adds resource consumption, the author notes that it also provides a good method to decouple storage from the host, allowing for the share of storage among multiple hosts, as shown below:
However, you might be wondering exactly how does iSCSI compare to SATA and SAS. The author begins to address this.
iSCSI is the storage transport but, at present, there is no such thing as an “iSCSI disk.” iSCSI arrays use SAS and SATA disks (which can also be SSDs) for storage, but the data is transported to hosts using iSCSI.
While SAS and SATA or networking interfaces, iSCSI is a networking protocol that can run across the infrastructure. In that sense, iSCSI is complementary, not contradictory, to SAS and SATA.


## EDC PHY AND PHYLESS SWITCH DESIGN DIFFERENCE
( https://bm-switch.com/index.php/blog/edc-phy-and-phyless-switch-design-difference/ )
Almost all modern bare metal switches are described as PHYless. What does it mean, what we need to consider?

We commonly interconnect network devices for distances below 100 meters with twisted pair or maybe 300 meters over OM3 multimode fiber for 10GBASE-SR. We can extend the span between devices to 10Km for with 10GBASE-LR, 40Km for 10GBase-ER or even 80Km for 10GBase-ZR. However, the signal path doesn’t end at the transceiver. The electronic engineer designing the circuit board must ensure that the signal received by the transceiver is transmitted to the switch ASIC (and vice versa) while maintaining signal integrity and that it a major challenge. Each of the signals traveling along the copper paths has to deal with hazards like electromagnetic interference (EMI), coupling and crosstalk, signal reflections, impedance mismatches, skew, attenuation and a host of other threats as they travel.

An SFP+ transceiver uses an electrical interface called SFI to communicate with the switching ASIC. Modern ASICs (such as Broadcom Trident and Intel Alta family) are capable of receiving and interpreting the SFI-signaled 10Gbps signal directly, such approach is called PHYless. However, if the copper path length is too long to keep signal quality at an acceptable level, we need to place PHY or SERDES, between the transceiver and the ASIC.

These chips can perform some or all of the functions:
    ( http://thenetworksherpa.com/hardware-signals-traces-and-circuit-boards/ )

    Clock recovery and re-timing (common to all chips)

    Full electronic dispersion compensation (EDC) – to deal with 10GBASE-LRM

    Electrical interface conversion (e.g. SFI to XFI, or SFI to KR)

    SERDES – Serial / Parallel conversion (e.g. single lane SFI to four-lane XAUI)

    PHY-layer sub-functions like the Physical Coding Sublayer (PCS).

XFI 和 SFI 接口系统设计
作者：刘 亮   应用工程师
( https://e2echina.ti.com/blogs_/b/signal_integrity_/archive/2015/08/27/xfi-sfi )

XFI(Ziffy音)和SFI是两个常见的10Gbps高速串行接口，都是连接ASIC芯片和光模块的电气接口。在传统光通信，数据交换机和服务器等上都可以找到些接口。两者之间有什么相似的地方？区别在哪里？我设计的系统接口是否满足标准要求？本博客将一一尝试介绍。

XFI和SFI的来源

XFI来源于XFP光模块标准的一部分，指的是连接ASIC芯片和XFP光模块的电气接口。XFP光模块标准定义于2002年左右，其内部的收和发方向都带有CDR电路。因此XFP模块尺寸比较大，功耗也比较大，这个对于需要多端口高密度的系统，比如数通交换机会是一个问题。为了解决这两个问题，2006年左右，SFP+光模块标准出来了，其内部没有CDR电路，相对于XFP模块，SFP+模块尺寸和功耗都变小了。对应SFP+的电气接口叫做SFI。

XFI接口先于SFI接口出现。电气特性上，由于SFP+模块内部没有CDR，可以预见SFI的电气特性要求会比XFI来的更严格一些，这个可以从接下来的介绍的眼图和抖动指标要求中可以清楚的看出来。
标准以及参考点

XFI接口的电气特性定义在INF-8077文档，SFI接口的电气特性定义在SFF8431文档。

对于电气特性要求，这两个标准都定义了A，B，C和D四个参考点。

A代表系统板上ASIC芯片高速信号输出，封装管脚的位置

B代表系统板电信号输出的位置，即来自A点的信号经过PCB走线以后到达光模块的电输入的位置

C代表系统板上接收来自光模块的电信号，信号输入的位置

D 代表系统板上ASIC芯片的高速信号输入，封装管脚的位置。即C点的信号经过PCB走线以后到达ASIC的电输入位置
                    D                              C' C
                    <----------------------------------   RX       XFP Module
                    <----------------------------------                 | 
                                                                       --- light
    ASIC/SerDes                                                        \ /
                                                                        | 
                                                             Driver
                    ---------------------------------->  TX  --\        | 
                    ---------------------------------->      --/       --- light
                                                                       \ /
                                                                        | 


## What the Heck is a TCAM
( http://www.enterprisenetworkingplanet.com/netsysm/article.php/3527301/On-Your-Network-What-the-Heck-is-a-TCAM.htm )
let's talk about TCAM hardware, Cisco SDM, and try to answer that elusive question: "why do I have to reboot my router to enable certain features, which in turn disables others?"
First, CAM stands for Content Addressable Memory. A CAM is a special type of memory; some would say the opposite of RAM. With normal computer memory (RAM) the operating system provides an address, and receives the data stored at the supplied address. With a CAM, the operating system supplies the data, and the CAM returns a list of addresses where the data is stored, if it finds any. Furthermore, a CAM searches the entire memory in one operation, so it is considerably faster than RAM.
CAMs are very expensive, so they aren't normally found in PCs. Even router vendors will sometimes skimp, opting to instead implement advanced software-based searching algorithms. Most commonly CAMs and TCAMs are found in network processing devices, including Intel IXP cards and various routers or switches.

The most commonly implemented CAMs are called binary CAMs. They search only for ones and zeros; a simple operation. MAC address tables in switches commonly get stored inside binary CAMs. You can bet that any switch capable of forwarding Ethernet frames at line-speed gigabit is using CAMs for lookups. If they were using RAM, the operating system would have to remember the address where everything is stored. With CAMs, the operating system can find what it needs in a single operation. In this case it's the switchport that data should be sent out, based on the given MAC address, i.e. the essence of a MAC table. Some older Cisco switches running CatOS even opted to call this table the CAM table, thereby causing great confusion across the land.

Finally, a TCAM is a Ternary CAM. This allows the operating system to match a third state, "X." The X state is a "mask," meaning its value can be anything. This lends itself well to networking, since netmasks (define) operate this way. To calculate a subnet address we mask the bits we don't care about, and then apply the logical AND operation to the rest. Routers can store their entire routing table in these TCAMs, allowing for very quick lookups.

Hardware can sometimes seem to work like magic, but it isn't always transparent. When configuring routers most people will run into a situation where enabling a new feature will require that the Cisco SDM (Switching Database Manager) template be changed. This template is actually a method Cisco uses to assign specific application to specific TCAM resources.

Some routers will allow you to manually specify how much TCAM space you want to allocate to a specific feature. Others aren't so nice. They make you choose from a few restrictive templates, which allocate the resources automatically based on a few predetermined settings. For example, on the Cisco 3750, we recently wanted to enable policy-based routing (PBR) to implement a layer 3 jail. The basic idea with template-only routers is that you have to choose where you want most of the optimizations, and compromise on the rest.

For this platform, there are four templates: default, routing, PBR, and VLAN. Each of these tries to allow for a bit more resources allocated to the specified task. For policy routing, we'd have to choose "routing" or "PBR," which in turn limits the amount of unicast MAC addresses (define) that can be held in TCAMs. Likewise, selecting a VLAN (define) template will make PBR impossible, but allow for more VLAN database information to be held in TCAMs. There are always compromises when we need to use more advanced features. Keeping true to the spirit of router operating systems, there are also some mysterious side effects when a new template is chosen. On our specific router, if the PBR template is chosen, the router will become unable to support VPN routing/forwarding tables (VRF). The next unfortunate gotcha is that with the IOS version that supports IPv6, you cannot even enable PBR. There is no template to allow both policy routing and IPv6.

Here are some more TCAM allocation examples. Just because, for instance, 8K is allocated to routing tables, this doesn't mean that you can only have a routing table of that size. There's always the fallback of process switching. Process switching means that everything will be done by the processor instead of in hardware (TCAMs). Processor intervention is not desirable, mostly because it is much slower than hardware lookups. Also, the processor is supposed to be used for things like sending logs to a syslog server and controlling SSH sessions. If a router doing process switching gets really busy, it may be unable to service your console access attempts.

Hardware is finite, and we always need more. More expensive routers don't always suffer from the constant struggle for TCAMs because they have enough to support most features that currently exist. Unfortunately, most companies won't want to purchase the latest and greatest router with seemingly endless TCAMs unless they can justify the added cost by showing a need for them right now. So we're stuck having to adjust TCAM allocations.

CAM (ternary content-addressable memory) is a specialized type of high-speed memory that searches its entire contents in a single clock cycle. 

The term “ternary” refers to the memory's ability to store and query data using three different inputs: 0, 1 and X. The “X” input, which is often referred to as a “don’t care” or “wildcard” state, enables TCAM to perform broader searches based on pattern matching, as opposed to binary CAM, which performs exact-match searches using only 0s and 1s.

Generally speaking, CAM is often described as the opposite of random access memory (RAM). To retrieve data on RAM, the operating system (OS) must provide the memory address where the data is stored. Data stored on CAM can be accessed by performing a query for the content itself, and the memory retrieves the addresses where that data can be found. Due to its parallel nature, CAM (and by extension TCAM) is much faster than RAM. However, it is not widely used in most electronics because it is expensive to build, consumes a lot of power and generates a high level of heat that must be dissipated.

TCAM is commonly found in networking equipment, such as high-performance routers and switches, to increase the speed of route look-up, packet classification, packet forwarding and access control list-based commands.

## 10G ETHERNET LAYER 1 OVERVIEW
    https://www.fmad.io/blog-10g-ethernet-layer1-overview.html
         |                                             PHY                          |
    MAC  |                  PCS            |               PMA                      |         PMD/MDI
    TX  ->  64b/66b encoder -> scramble    ->   10Ghz serializer                    ->  SFP+              <->  the cable
    RX  <-  64b/66b decoder <-  descramble <-   clock recovery <- 10G deserialize   <-  transceiver  

Lets start with the basic building blocks of a 10G ethernet system. The diagram above maps out the major components in english (not 802.3 clause 49 legalize).

MAC Media Access Control. Usually this is considered the lowest of low level components, however this is today's starting point. Its connected to the PHY using XAUI or RXAUI protocol which is an 8b/10b encoded bit-stream and includes everything required to extract packets. Note the "extract packets" part as if your from a software background the idea of always sending data on every single cycle, regardless of idle or not, seems quite un-natural. We will get to that a bit later, for now consider the MAC`s interface a full line rate no gap stream of bits.

PHY. Traditionally the PHY was a completely separate chip, e.g the classic NetLogic AEL2005 which handled all the nasty encoding/decoding serialization/deserialization at 10Ghz. This separation required a standardized protocol between the MAC & PHY thus the XAUI protocol was created. The PHY`s main job is to translate the XAUI data stream into a serial link which is connected to the SFP+ transceiver's. Now days the PHY is fully integrated and part of the ASIC or FPGA making the separation more logical than a real physical connector.

PCS Physical Coding Sublayer. For 10GBaseR the PCS is fairly simple compared to 40G, 100G and some of the more exotic backplane protocols. Why simpler? the PCS for 40G/100GBaseR must handle alignment, distribution, lane skew, error correction and synchronization, all of which are not part of the 10GBaseR spec. Straight 10GBaseR PCS only requires 64b66b encode/decode and scramble/descramble logic. One of the great design decisions about 40G and 100G is, it utilizes the same basic 10G foundations, with fairly minor variations for the different protocols. This substantially reduces the technology risk and resources required to support 40G/100G as most of the ground work has already been done. In short, the primary purpose of the PCS is to translate the XAUI bitstream into a 64b/66b encoding and scramble the bits that are then sent to the PMA unit for serialization.

PMA Physical Medium Attachment This unit converts the scrambled 64b/66b bitstream into a high speed 10.3125Ghz serial link or decodes the 10.3125Ghz serial link into an 64b/66b bitstream. On the receiver side it also performs clock recovery which we will go into detail in a different post. Typically most of the work is done by the hardmacro transceiver's on the chip, as FPGA`s and ASIC`s can not run a 10Ghz clock across the chip, but it can run very high clocks in very small areas of the chip, which is exactly what the hardware designers did.

PMD/MDI Medium Dependant Interface At this point, its about what kind of SFP+ transceiver's is plugged in. This is where the rubber meets the road, as the 10Ghz serial stream of 1's and 0's is converted into electrical impulses in the case of Copper cabling, or converted into photons when fiber is used.

For 10Gbit network capture devices, the MAC + PCS + PMA are combined into the same FPGA chip. All major fpga vendors support high speed on-chip transceiver`s, since the Xilinx Virtex6 and Altrea StratixV. Combinding the functionality enables reduction in latency, reduction in costs and an increase in flexibility. Also our own 10G, 40G and 100G capture systems implementing the entire MAC+PCS+PMA in a single fpga, without any PHY chip. We will dig into each of the above components in signficiant detail over the next few posts, stay tuned.

    # explain from TI
    https://e2e.ti.com/blogs_/b/analogwire/archive/2014/06/16/get-connected-serdes-interfaces
                    max                          |          PHY          |
    higher layers - mac(media access control)  <-MII->  PCS - PMA - PMD    <-MDI->  media
    The physical coding sublayer or PCS allows the transfer of information to and from the MAC or other PCS clients like a repeater. The PCS performs frame delineation, encoding/de-coding such as 8b/10b or 64b/66b, fault information transport, deskew of received data, and data restoration.

    The physical media attachment or PMA sublayer is responsible for local and remote loopback testing, PMA data framing, and test pattern generation (i.e. PRBS7 /CRPAT). The PMA layer is also where the rate per lane and the number of lanes is set. For example, some devices support multiple modes of operation and can be set up to run at 1x10Gbps, 2x5Gbps, or 4x2.5Gbps.

    The physical media dependent or PMD sublayer is where the PHY interacts with the properties of the actual medium. The media can be a single or multimode optical fiber, CAT5 STP/UTP, backplane, or copper cable/wire. The PMD defines the details and standardizes the transmission and reception of the data stream on the medium.

## MII,GMII, RGMII,SGMII,XAUI,SPI
MII   - Media Independent Interface - 100 Mbps
GMII  - Gigabit MII - 1 Gbps (24 pins) (8TX - 8RX)
RGMII - Reduced GMII - 1 Gbps (12 pins) (4TX - 4RX)
SGMII - Serial GMII - 1 Gbps (8 pins) (2TX - 2RX)
XAUI  - XGMII Extender - 10 Gbps (XY pins) (8TX - 8RX)
XLAUI - 40G
SPI-4.2 - System Packet Interface Level 4, Phase 2 (16TX - 16RX)

The Media Independent Interface (MII) is a standard interface used to connect a Fast Ethernet (i.e. 100Mb/s) MAC-block to a PHY. The MII may connect to an external transceiver device via a pluggable connector (see photo) or simply connect two chips on the same printed circuit board. Being media independent means that any of several different types of PHY devices can be used without redesigning or replacing the MAC hardware. The equivalents of MII for other speeds are AUI (for 10 megabit Ethernet), GMII (for gigabit Ethernet), and XAUI (for 10 gigabit Ethernet).

Gigabit Media Independent Interface (GMII) is an interface between the Media Access Control (MAC) device and the physical layer (PHY). The interface defines speeds up to 1000 Mbit/s, implemented using an eight bit data interface clocked at 125 MHz, and is backwards compatible with the Media Independent Interface (MII) specification. It can also operate on fall-back speeds of 10/100 Mbit/s as per the MII specification.
Data on the interface is framed using the IEEE Ethernet standard. As such it consists of a preamble, start of frame delimiter, Ethernet headers, protocol specific data and a cyclic redundancy check (CRC) checksum.
The GMII interface is defined in IEEE Standard 802.3, 2000 Edition [1].

Reduced Gigabit Media Independent Interface (RGMII) specifies a particular interface between an Ethernet MAC and PHY.
RGMII uses half the number of pins as used in the GMII interface. This reduction is achieved by clocking data on both the rising and falling edges of the clock, and by eliminating non-essential signals (carrier-sense and collision-indication). Thus RGMII consists only of: RXC, RD[3:0], RX_CTL, TXC, TXD[3:0], and TX_CTL (12 pins, as opposed to GMII's 24).
Unlike GMII, the transmit clock signal is always provided by the MAC on the TXC line, rather than being provided by the PHY for 10/100 Mbit/s operation and by the MAC at 1000 Mbs.
RGMII supports Ethernet speeds of 10 Mbit/s, 100 Mb/s and 1000 Mbit/s.

The Serial Gigabit Media Independent Interface (SGMII) is a sequel of MII, a standard interface used to connect an Ethernet MAC-block to a PHY. It is used for Gigabit Ethernet (contrary to Ethernet 10/100 for MII). It differs from GMII by its low-power and low pin count serial interface (commonly referred to as a SerDes). To carry frame data and link rate information between a 10/100/1000 PHY and an Ethernet MAC, SGMII uses a differential pair for data signals and for clocking signals, with both being present in each direction (i.e., transmit and receive), giving 8 signal lines in total.

XAUI is a standard for extending the XGMII (10 Gigabit Media Independent Interface) between the MAC and PHY layer of 10 Gigabit Ethernet (10GbE). XAUI is pronounced "zowie", a concatenation of the Roman numeral X, meaning ten, and the initials of "Attachment Unit Interface".
The XGMII Extender, which is composed of an XGXS at the MAC end, an XGXS at the PHY end and a XAUI between them, is to extend the operational distance of the XGMII and to reduce the number of interface signals. Applications include extending the physical separation possible between MAC and PHY components in a 10 Gigabit Ethernet system distributed across a circuit board.

System Packet Interface-4 Phase 2 (SPI-4.2) is a protocol used for data transfer between link layer and physical layer. It is an interface for packet and cell transfer between a physical (PHY) layer device and a link layer device, for aggregate bandwidths of OC-192 ATM and Packet over SONET (POS), as well as for 10 Gb/s Ethernet applications. The SPI 4.2 protocol defines a 311 MHz (minimum) dual data rate (DDR) operation for a 16-bit data bus, effectively yielding a 10 Gb/s data rate. In order to achieve optimum performance, the architecture outlined below does not add any padding data/control packets between two consecutive back-to-back transfers. Also, in order to transfer data efficiently, the architecture incorporates an SPI Performance monitor which reflects the arbitration status and FIFO status measured over a period of time, which can be analyzed by the firmware. This feature helps the firmware to change the calendar sequence or arbitration logic of a specific port, thus achieving a significant improvement in SPI 4.2 channel utilization. Most of the blocks used in the IP are configurable and can also be re-used in protocol implementation of a similar kind.

## PHY internal
        MAC
         |  GMII XGMII XLGMII CGMII
   ---PLS / PCS <--------
   |     | XSBI         |
   |  FEC / RS-FEC     AUI
   |     |              |
  PHY   PMA     <--------          PHY
   |     | XLAUI CAUI   |
   |    PMA             |
   |     | nPPI         |
   |    PMD            MDI         PMD
   -----AN              |           AN
         ^              |           ^
         |              |           |
         |MDI          \ /     MDI  |
         ----------> Medium <-------

    PLS：PhysicalSublayer Signaling，对MAC给的信息进行传递，只在1Mb/s、10Mb/s的应用场景才出现；
    PCS：Physical Coding Sublayer，对MAC给的信息进行编码，应用于≥100 Mb/s的应用场景，比如完成8B/10B、64B/66B、256B/257B编码；
    FEC：Forward Error Correction，前向纠错，与10GBase-R、40GBase-R的PCS 搭配；
    RS-FEC：Reed-Solomon前向纠错，比单纯的FEC纠错能力更强，与100GBase-R的PCS 搭配，采用256B/257B编码；
    PMA：Physical Medium Attachment，
    PMD：Physical Medium Dependent，
    AN: Auto-Negotiation Function，自动协商，使背板两侧的Device能够互换信息以发挥出彼此最大的优势；

AN:
    https://www.fiberoptics4sale.com/blogs/archive-posts/95041222-what-is-ethernet-auto-negotiation

    Auto-negotiation is the feature that allows a port on a switch, router, server, or other device to communicate with the device on the other end of the link to determine the optimal duplex mode and speed for the connection.
    The driver then dynamically configures the interface to the values determined for the link.

    1. Speed:
    Speed is the rate of the interface, usually listed in megabits per second (Mbps). Common Ethernet speeds include 10 Mbps, 100 Mbps, and 1,000 Mbps. 1,000 Mbps Ethernet is also referred to as Gigabit Ethernet.

    2. Duplex
    Duplex refers to how data flows on the interface.

    On a half-duplex interface, data can only be transmitted or received at any given time. A conversation on a two-way radio is usually half-duplex – each person must push a button to talk, and, while talking, that person can not listen.
    A full-duplex interface, on the other hand, can send and receive data simultaneously. A conversation on a telephone is full duplex.

    :: HOW AUTO-NEGOTIATION WORKS
    What Auto-Negotiation Does Not Do:

    When auto-negotiation is enabled on a port, it does not automatically determine the configuration of the port on the other side of the Ethernet cable and then match it.
    This is a common misconception that often leads to problems.
    Auto-negotiation is a protocol, and as with any protocol, it only works if it’s running on both sides of the link.
    So if one side of a link is running auto-negotiation, and the other side of the link is not, auto-negotiation CANNOT determine the speed and duplex configuration of the other side.
    If auto-negotiation is running on the other side of the link, the two devices decide TOGETHER on the best speed and duplex mode. Each interface advertises the speeds and duplex modes at which it can operate, and the best match is selected (higher speed and full duplex are preferred).

    :: WHEN AUTO-NEGOTIATION FAILS
    When auto-negotiation fails on 10/100 links, the most likely cause is that one side of the link has been set to 100/full, and the other side has been set to auto-negotiation. This results in one side being 100/full, and the other side being 100/half.

    1. Half-Duplex
    The following figure shows a half-duplex link. In a half-duplex environment, the receiving (Rx) line is monitored. If a frame is present on the Rx link, no frames are sent until the Rx line is clear. If a frame is received on the Rx line while a frame is being sent on the transmitting (Tx) line, a collision occurs. Collisions cause the collision error counter to be incremented – and the sending frame to be retransmitted – after a random back-off delay.

    2. Full-Duplex
    The following figure shows a full-duplex link. In full-duplex operation, the Rx line is not monitored, and the Tx line is always considered available. Collisions do not occur in full-duplex mode because the Rx and Tx lines are completely independent.

    3. Misconfiguration
    When one side of the link is full-duplex, and the other side is half-duplex, a large number of collisions will occur on the half-duplex side.
    Because the full-duplex side sends frames without checking the Rx line, if it’s a busy device, chances are it will be sending frames constantly.
    The other end of the link, being half-duplex, will listen to the Rx line, and will not transmit unless the Rx line is available. It will have a hard time getting a chance to transmit, and will record a high number of collisions, resulting in the device appearing to be slow on the network.
    This issue may not be obvious because a half-duplex interface normally shows collisions. The problem should present itself as excessive collisions.
    The following figure shows a link where auto-negotiation has failed.

    In the real world, if you see that an interface that is set to auto-negotiation has negotiated to 100/half, chances are the other wide is set to 100/full. 100 Mbps interfaces that do not full duplex are rare, so properly configured auto-negotiation ports should almost never end up configured for half duplex.

    :: AUTO-NEGOTIATION BEST PRACTICES
    Using auto-negotiation to your advantage is as easy as remembering one simple rule:

    Make sure that both sides of the link are configured the same way.
    If one side of the link is set to auto-negotiation, make sure the other side is also set to auto-negotiation. If one side is set to 100/full, make sure the other side is also set to 100/full.
    Be careful about using 10/full, as full duplex is not supported on all 10Base-T Ethernet devices.

    :: GIGABIT ETHERNET AUTO-NEGOTIATION
    Gigabit Ethernet uses a substantially more robust auto-negotiation mechanism than the one described above.

    Gigabit Ethernet should thus always be set to auto-negotiation, unless there is a compelling reason to do so (such as an interface that will not properly negotiate). Even then, this should be considered a temporary workaround until the misbehaving part can be replaced.

## Ethernet Frame
In computer networking, an Ethernet frame is a data link layer protocol data unit and uses the underlying Ethernet physical layer transport mechanisms. In other words, a data unit on an Ethernet link transports an Ethernet frame as its payload.[1]
An Ethernet frame is preceded by a preamble and start frame delimiter (SFD), which are both part of the Ethernet packet at the physical layer. Each Ethernet frame starts with an Ethernet header, which contains destination and source MAC addresses as its first two fields. The middle section of the frame is payload data including any headers for other protocols (for example, Internet Protocol) carried in the frame. The frame ends with a frame check sequence (FCS), which is a 32-bit cyclic redundancy check used to detect any in-transit corruption of data.
A data packet on the wire and the frame as its payload consist of binary data. Ethernet transmits data with the most-significant octet (byte) first; within each octet, however, the least-significant bit is transmitted first.[a]
The internal structure of an Ethernet frame is specified in IEEE 802.3.[1] The table below shows the complete Ethernet packet and the frame inside, as transmitted, for the payload size up to the MTU of 1500 octets.[b] Some implementations of Gigabit Ethernet and other higher-speed variants of Ethernet support larger frames, known as jumbo frames.

Layer	                       | Preamble	Start of frame delimiter  | MAC destination	MAC source	802.1Q tag (optional)	Ethertype (Ethernet II) or length (IEEE 802.3)	Payload	        Frame check sequence (32‑bit CRC) |  Interpacket gap  |
                               | 7 octets	1 octet	                  | 6 octets	    6 octets	(4 octets)	            2 octets	                                    46‑1500 octets	4 octets	                      |  12 octets        |
Layer 2 Ethernet frame		   |                                      |                                        ← 64–1522 octets →                                                                                             |	                  |
Layer 1 Ethernet packet & IPG  |	                                                        ← 72–1530 octets →	                                                                                                              |   ← 12 octets →   |


# Retimer /Redriver / Repeater
    https://www.asteralabs.com/post/pci-express-retimers-vs-redrivers-an-eye-popping-difference

    Repeater: An imprecise term for an extension device [2]. (This term causes confusion … please don’t use it!)
    Redriver: A non-protocol-aware software-transparent extension device [2].
    Retimer: A physical layer protocol-aware, software-transparent extension device that forms two separate electrical link segments [2].

    A redriver is a mostly analog reach extension device designed to boost the high-frequency portions of a signal to counteract the frequency-dependent attenuation caused by the interconnect: the central processing unit (CPU) package, system board, connectors and so on. A redriver’s data path typically includes a continuous time linear equalizer (CTLE), a wideband gain stage and a linear driver. In addition, redrivers often have input loss-of-signal threshold and output receiver (Rx) detection capability. Figure 1 illustrates a typical redriver block diagram.

    A retimer is a mixed signal analog/digital device that is protocol-aware and has the ability to fully recover the data, extract the embedded clock and retransmit a fresh copy of the data using a clean clock. In addition to the CTLE and wideband gain stages also found in a redriver, retimers contain a clock and data recovery (CDR) circuit, a decision feedback equalizer (DFE) and a transmit (Tx) finite impulse response (FIR) driver. Finite state machines (FSMs) and/or a microcontroller typically manage the automatic adaptation of the CTLE, wideband gain, DFE and FIR driver, and implement the PCIe link training and status state machine (LTSSM). Figure 2 illustrates a typical retimer block diagram.

    In simple terms, a redriver amplifies a signal, whereas a retimer retransmits a fresh copy of the signal.

# EOBC
a xxx is a composite system with supervisor(s) and linecards, with intelligence distributed over the linecards.
For management and control purposes  a different path is built inside the xxx different from the switching fabric used to move user traffic. The idea is that control traffic has to use different paths then user traffic to build a stable reliable system avoiding control packets to compete for BW resources with user traffic.
These management links are called out of band control, so EOBC should stand for ethernet out of band communication.
Using these management links the supervisor polls the various linecards to understand if they are alive.
Also through these ooB links the CEF table is copied to linecards hosting DFC submodules for distributed CEF.
The OOB management uses IPv4 for communication and modules are assigned unique IP addresses within the 127.0.0.0/8 that is dedicated to internal communication in a  node (loopback).
On the xxx there are show commands related to EOBC activity.
Also communication between supervisors is a form of EOBC, the master supervisor takes control of the chassis and of the EOBC communication.

# Linux network protocol stack
net/socket.c
    core_initcall(sock_init);	/* early initcall */

net/ipv4/af_inet.c
    fs_initcall(inet_init);

net/core/dev.c
    subsys_initcall(net_dev_init);
